import streamlit as st
import torch
from transformers import BertTokenizerFast, BertForSequenceClassification


# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞

@st.cache_resource
def load_model_and_tokenizer():
    tokenizer = BertTokenizerFast.from_pretrained("bert_tokenizer")
    model = BertForSequenceClassification.from_pretrained("bert_model")
    model.eval()
    return model, tokenizer

model, tokenizer = load_model_and_tokenizer()
device = torch.device("cpu")
model.to(device)

# 2. –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit

st.set_page_config(page_title="üé≠ –ê–Ω–∞–ª–∏–∑ –æ—Ç–∑—ã–≤–æ–≤ (BERT)", page_icon="ü§ñ", layout="centered")

st.title("ü§ñ –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ —Å –ø–æ–º–æ—â—å—é BERT")
st.markdown("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞, –∏ –º–æ–¥–µ–ª—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç –µ–≥–æ **–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ** üòä –∏–ª–∏ üò°")

text = st.text_area("‚úçÔ∏è –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç:", height=150)

if st.button("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å"):
    if not text.strip():
        st.warning("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞!")
    else:
        inputs = tokenizer(
            [text],
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=128
        ).to(device)

        with torch.no_grad():
            outputs = model(**inputs)
            probs = torch.nn.functional.softmax(outputs.logits, dim=1)
            pred = torch.argmax(probs, dim=1).item()

        st.markdown("---")
        if pred == 1:
            st.success("üòä **–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç–∑—ã–≤**")
        else:
            st.error("üò° **–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–∑—ã–≤**")

st.markdown("---")
st.caption("–ü—Ä–æ–µ–∫—Ç: –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ IMDB ‚Äî –ú—É–∫–∞–∂–∞–Ω–æ–≤ –ê–¥–∏–ª—å üéì")

#streamlit run app_bert.py